<!doctype html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8">

    <title>
        Bayesian Linear Regression
    </title>

    <!-- CDNs -->
    <!-- AngularJS -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.20/angular.min.js"></script>

    <!-- D3js -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.4.11/d3.min.js"></script>

    <!-- Katex -->
    <link href="katex/katex.min.css" type="text/css" rel="stylesheet">
    <script type="text/javascript" src="/katex/katex.min.js"> </script>



    <!--&lt;!&ndash; Local Development &ndash;&gt;-->
    <!--&lt;!&ndash; AngularJS &ndash;&gt;-->
    <!--<script type="text/javascript" src="/js/jquery.min.js"></script>-->
    <!--<script type="text/javascript" src="/js/angular.js"></script>-->

    <!--&lt;!&ndash; D3js &ndash;&gt;-->
    <!--<script type="text/javascript" src="/js/d3.min.js"></script>-->

    <!--&lt;!&ndash; MathJax &ndash;&gt;-->
    <!--<script src="/js/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->

    <!-- Essay -->
    <style>
        @import url("css/custom.css");
    </style>
    <script type="text/javascript" src="/js/talk.js"></script>

</head>
<body ng-app="regressionEssay">
<a href="https://github.com/ColCarroll/lin_reg_essay"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/365986a132ccd6a44c23a9169022c0b5c890c387/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f7265645f6161303030302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png"></a>
<header>
    <aside>September 18, 2014</aside>
    <a href="colindcarroll.com">Colin Carroll</a>
</header>
<h1>A Bayesian Approach to <span class="math">L^1</span> and <span class="math">L^2</span> Regularization in Machine Learning</h1>
<h3>Colin Carroll</h3>

<h2><a href="#introduction" name="introduction">></a>Introduction</h2>
<div class="p">
    There are two common tasks in machine learning: <em>regression</em> tasks and <em>classification</em>
    tasks. Examples of classification tasks include predicting the species of an iris based on
    <a href="http://en.wikipedia.org/wiki/Iris_flower_data_set">petal and sepal measurements</a>, or predicting who will
    win a <a href="http://fivethirtyeight.com/interactives/senate-forecast/">Senate race</a> or
    <a href="http://www.lasvegas.com"> football game</a>.
    Broadly each takes some set of inputs and then outputs one of a discrete set of labels (species of iris, Senatorial candidate, or football team).  Typically, the output will
    actually be a probability of some data point having some label.  A regression task will predict a <em>real
    valued</em> output.  Perhaps this would be used to estimate stock prices, forecast inventory, or predict the score of a
    a football game.
</div>

<div class="p">
    Linear regression can get a bad rap for sounding boring.  Much like in linear algebra, where solving <span class="math">A \vec{x} = \vec{b}</span> turns out to be surprisingly useful, studying linear regression - how to build a model, how to
    tune a model, and what sorts of performance to expect - can yield impressive results in practice.  In particular,
    one finds that many methods with sexier names are built on top of linear regression.
    <a href="http://en.wikipedia.org/wiki/Logistic_regression">Logistic regression</a>, a popular choice in
    classification tasks, is built on top of linear regression, and
    <a href="http://en.wikipedia.org/wiki/Artificial_neural_network">neural nets</a>, which seem to be trendy these
    days, use linear regression as their building blocks.
</div>

<h3><a href="#notation" name="notation">></a>Notation</h3>
<div class="p">
    The symbols on this page are displayed using <a href="http://khan.github.io/KaTeX/">KaTeX</a>, rather than
    <a href="http://www.mathjax.org/">MathJax</a>, both as an experiment in KaTeX and to improve performance.  Since KaTeX is
    still in development, a few shortcuts had to be taken.  Below is a list of things I did in MathJax that, as far
    as I know, still cannot be done in KaTeX (though, to emphasize, I think KaTeX is a terrific project, and chose to
    use it for the performance increase).
    <ul>
        <li>
            <code>\mathcal</code>, <a href="http://en.wikipedia.org/wiki/Blackboard_bold"><code>\mathbb</code></a>
            do not exist, so sets aren't fancy, and the real numbers are just a capital R. (Note in the linked
            wikipedia entry that Knuth suggested using an actual bold in place of blackboard bold in print, but
            <code>\mathbf</code> is also not implemented.)
        </li>
        <li>
            Matrices (and environments in general) do not exist, though their absence
            <a href="https://github.com/Khan/KaTeX/issues/43">is noted</a>.
        </li>
        <li>
            <code>\propto</code> isn't implemented yet, so I keep the constants around, which adds a bit to the
            notational burden on the reader.
        </li>
        <li>
            <code>\ell</code> doesn't exist, so
            <a href="http://en.wikipedia.org/wiki/Lp_space#The_p-norm_in_finite_dimensions">little lp spaces</a> do not
            look as sweet.
        </li>
        <li>
            <code>\nabla</code> is missing, so for the gradient, I use a capital D.  In a wildly unscientific
            survey of mathematicians, I got a "I would say so, yeah" and a "geez, maybe" when asked whether D and
            <code>\nabla</code> were the same thing, so I'm going for it.
        </li>
    </ul>
</div>

<h2><a href="#setup" name="setup">></a>Setup</h2>
<div class="p">
    At its most basic, a linear model is one of the form
    <div class="math">
        y(\vec{x}, \vec{w}) = w_0 + x_1 w_1 + \cdots + w_Nx_N,
    </div>
    where <span class="math">\vec{x} = (x_1, \ldots, x_N) \in R^N</span> are called <em>features</em>, and
    <span class="math">\vec{w} = (w_0, \ldots, w_N) \in R^{N+1}</span> are called <em>weights</em>.  One is typically
    given some training data
    <div class="math">
        D = \{(y_1, \vec{x}_1),\ldots,(y_d, \vec{x}_d)\},
    </div>
    and asked to find a model which minimizes
    <div class="math">
        loss(\vec{w}) = \sum_{j=1}^d (y_j - y(\vec{x}_j, \vec{w}))^2.
    </div>
    Below, you may click on the plot to generate a random data set, and then manually choose values
    <span class="math">w_0</span>, <span class="math">w_1</span> to
    try to fit <span class="math">y(x, \vec{w}) = w_0 + w_1 x</span> to the data.
</div>

<div ng-controller="ManualRegression" class="figure">
    <div ng-click="cycleData()">
        <plot-line-points point-data="data" line-data="plotData"></plot-line-points>
    </div>
    <div class="p">
        <span class="math">
            \vec{w} = (w_0, w_1) =
        </span>(
            <input type="number" step=0.1 ng-model="w0" ng-change="updatePlot()">,
            <input type="number" step=0.1 ng-model="w1" ng-change="updatePlot()">
        )
        <br>
        Current model: <span katex-bind="tex"></span>
    </div>
    <div class="p">Current loss: {{error.toFixed(2)}}</div>
</div>

<h2><a href="#advancedSetup" name="advancedSetup">></a>Advanced Setup</h2>

<div class="p">
    That was likely highly frustrating, since many (most?) of these data sets (like real data sets) come from functions that rely non-linearly on
    their inputs.  One might consider rainfall in a location as a function of the day of year, which would probably have
    some sort of periodic relationship, or weight of a person given their height, which we might expect has a polynomial
    relationship (since weight is roughly proportional to volume, and height is a measure of length).
</div>

<div class="p">
    We deal with this by fitting our
    model using <em>basis functions</em>, <span class="math">\vec{\phi} = (\phi_1, \ldots, \phi_n)</span>, where
    <span class="math">\phi_j: R^N \to R</span>.  Then we have model

    <div class="math">
        y(\vec{x}, \vec{w}) = w_0 + \sum_{j=1}^n w_j \vec{\phi}_j(\vec{x})
    </div>
    which relies non-linearly on <span class="math">\vec{x}</span>.  We can write this more compactly by setting
    <span class="math">\phi_0(\vec{x}) := 1</span>, so
    <div class="math">
        y = \vec{\phi}(\vec{x}) \cdot \vec{w}.
    </div>
</div>

<div class="p">
    In practice, some popular choices for basis functions include:

    <ul ng-controller="basisCtrl">
        <li><em><a href="http://en.wikipedia.org/wiki/Polynomial">Polynomials</a>.</em>
            For a one dimensional feature set, this means including basis functions
            <div class="math">
                \phi_j(x) = x^j,
            </div>
            so that instead of modeling  <span class="math">y = w_0 + w_1 x</span>, we can now write
            <div class="math">
                y(\vec{w}, x) = \sum_{j=0}^n w_j  \phi_j(x) = w_0 + w_1 x + w_2 x^2 + \cdots + w_n x^n,
            </div>
            for some value of <span class="math">n</span>.  As an example when <span class="math">\vec{x}</span> is of higher dimension,
            <span class="math">\vec{x} = (x_1, \ldots, x_N)</span>, you may get the second degree polynomials by defining
            <span class="math">\phi_{j, 0}(\vec{x}) = x_j</span>, and <span class="math">\phi_{j,k}(x) = x_j x_k</span>.
            Now you will have <span class="math">\binom{N}{2}</span> basis functions (pronounced "N choose 2", and, in
            fact, equal to <span class="math">\frac{N(N-1)}{2}</span>), and
            <div class="math">
                y(\vec{w}, \vec{x}) = \sum_{j, k = 0; j \leq k}^N w_{j,k}\phi_{j,k}(\vec{x}).
            </div>

            A shortcoming of polynomials is that they tend to get very large very fast away from points you have
            trained on, since <span class="math">\lim_{x\to\pm \infty}|x^j| = \infty</span> for any positive value of
            <span class="math">j</span>. This can lead to ridiculous predictions.

            <div class="figure">
                <plot-line line-data="polyData"></plot-line>
                <div>
                    <span katex-bind="polyTex"></span>
                </div>
                <div>
                    Edit degree:
                    <input type="number" step="1" ng-model="polyDegree" ng-change="updatePoly()">
                </div>
            </div>
        </li>

        <li> <em><a href="http://en.wikipedia.org/wiki/Sigmoid_function">Sigmoids</a>.</em>
            These may be defined casually as having
            an "S" shape, and carefully as being monotone (either always increasing or decreasing), and converging to a
            finite value in either direction.  Concretely, one such family is
            <div class="math">
                \sigma_{m,b}(x) = \frac{1}{1 + e^{-m(x + b)}},
            </div>
            where <span class="math">m</span> controls the "spread" of the sigmoid, and <span class="math">b</span> the
            "location".  Another popular choice for<span class="math">\sigma_{m,b}</span> is <span class="math">\tanh(m(x+b))</span>.  One might think of a sigmoid as modeling some change that happens around the point <span class="math">b</span> with some amount of abruptness controlled by <span class="math">m</span>.  You might generate many of
            these sigmoids by selecting some grid of locations and spreads in your feature space.
            <div class="figure">
                <plot-line line-data="sigmoidData"></plot-line>
                <div>
                    <span katex-bind="sigmoidTex"></span>
                </div>
                <div>
                    Edit location:
                    <input type="number" step="0.1" ng-model="sigmoidLoc" ng-change="updateSigmoid()">
                </div>
                <div>
                    Edit spread:
                    <input type="number" step="1" ng-model="sigmoidSpread" ng-change="updateSigmoid()">
                </div>
            </div>
        </li>

        <li> <em><a href="http://en.wikipedia.org/wiki/Gaussian_function">Gaussians</a>.</em>
            We'll later deal with these in a statistical fashion, but right now they're just a friendly shape.  Similarly
            to sigmoids, these functions have a local effect on a model.  They are defined as a two parameter family,
            with the parameters controlling spread and location.  We write
            <div class="math">
                \phi_{m,b}(x) = e^{\frac{(x - b)^2}{2m^2}}.
            </div>
            <div class="figure">
                <plot-line line-data="gaussData"></plot-line>
                <div>
                    <span katex-bind="gaussTex"></span>
                </div>
                <div>
                    Edit location:
                    <input type="number" step="0.1" ng-model="gaussLoc" ng-change="updateGauss()">
                </div>
                <div>
                    Edit spread:
                    <input type="number" min="0" step="0.1" ng-model="gaussSpread" ng-change="updateGauss()">
                </div>
            </div>
        </li>
    </ul>
</div>

<h2><a href="#fittingModel" name="fittingModel">></a>Fitting the Model</h2>

<div class="p">
    Up until now, we have been using everyone's favorite method of minimizing functions, namely by eyeballin' them.
    The focus of this essay is not optimization, but we should mention one bad and two good methods for minimizing
    functions.
</div>


<div class="p">
    First, recall that we are given
    <div class="math">
        D = \{(y_1, \vec{x}_1),\ldots,(y_d, \vec{x}_d)\},
    </div>
    have decided on some set of basis functions
    <div class="math">
        \vec{\phi} = (\phi_0, \ldots, \phi_n),
    </div>
    and seek to find a vector
    <div class="math">
        \vec{w} = (w_0, \ldots, w_n)
    </div>
    which minimizes the loss function
    <div class="math">
        loss(\vec{w}) = \sum_{j=1}^d (y_j - \vec{\phi}(\vec{x}_j) \cdot \vec{w}))^2.
    </div>
    We outline three methods for finding the minimum.
</div>

<ol>
    <li>
        <em>Guessing</em>
        This is a reasonable first try, but ultimately a Bad Idea.  Given a function <code>loss</code> that evaluates
        the loss of a weight, you might write a loop like
        <pre><code>
            best_w = -10
            min_loss = loss(-10)
            for w in range(-10, 10, 0.1):
                if loss(w) < min_loss:
                    best_w = w
                    min_loss = loss(w)
            print(best_w)
        </code></pre>
        Staring at this loop, a few questions might strike you:
        <ul>
            <li>
                Why did we iterate from -10 to 10?  Why not -1 to 1?  Why not -1,000 to 1,000?
            </li>
            <li>
                What if we need more accuracy?
            </li>
            <li>
                What if <span class="math">w</span> is n dimensional?  Instead of 200 points to check, we'll have
                <span class="math">200^{n + 1}</span>, which is a big number.
            </li>
        </ul>
        <div class="p">
            There are good answers to these questions, and if you think about them long enough, you might accidentally
            invent calculus. Rather than belabor the point, let's move on to a calculus based approach.
        </div>
    </li>
    <li>
        <em>Calculus and linear algebra</em>
        <div class="p">We're going to swing from an approach where we hope to be wildly lucky - and then will be only
            approximately correct - to one where we're guaranteed to hit the exact answer square on the head.  One
            recalls that a big theme in calculus is finding extreme points. So we can take a derivative of
            <span class="math">loss(\vec{w})</span> with respect to <span class="math">\vec{w}</span>, set it equal to
            zero, and solve for <span class="math">\vec{w}</span>.
        </div>

        <div class="p">
            The gradient
            <div class="math">
                D_{\vec{w}}loss(\vec{w}) = 2 \sum_{j = 1}^d(\vec{\phi}(\vec{x}_j)\cdot \vec{w} - y_j) \vec{\phi}(\vec{x}_j)
            </div>
            can be rewritten using matrix notation by defining <span class="math">\Phi</span> as a
            <span class="math">d \times (n + 1)</span> matrix whose <span class="math">j</span>th row and
            <span class="math">k</span>th column is <span class="math">\phi_k(x^j)</span>.  Then writing
            <div class="math">
                \vec{y} = ( y_1, y_2, \ldots, y_d)^T,
            </div>
            we are solving
            <div class="math">
                D_{\vec{w}} loss(\vec{w}) = \Phi^T(\Phi \vec{w} - \vec{y}) = \vec{0},
            </div>
            or
            <div class="math">
                \Phi^T\Phi w = \Phi^T y.
            </div>
        </div>

        <div class="p">

            Note that <span class="math">\Phi</span> is a <span class="math">d \times (n + 1)</span> matrix, where
            <span class="math">d</span> is a big number (in particular, <span class="math">d > n + 1</span>). However,
            <span class="math">\Phi^T\Phi</span> is an <span class="math">(n + 1) \times (n+1)</span>, (probably)
            invertible matrix.  So we can solve for <span class="math">\vec{w}</span> by noting that, if
            <div class="math">
                \Phi^T\Phi \vec{w} = \Phi^T \vec{y},
            </div>
            then
            <div class="math">
                (\Phi^T \Phi)^{-1} (\Phi^T \Phi) \vec{w} = (\Phi^T \Phi)^{-1} \Phi^T \vec{y},
            </div>
            and simplifying gives
            <div class="math">
                \vec{w} = (\Phi^T \Phi)^{-1} \Phi^T \vec{y}.
            </div>

            This solution will minimize the loss function, and be an exact answer.  One is obliged to report also that
            <span class="math">(\Phi^T \Phi)^{-1} \Phi^T</span> is called the
            <em><a href="http://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_pseudoinverse">pseudoinverse</a></em> of
            <span class="math">\Phi</span>.  Back of the envelope calculations say that as <span class="math">D</span>
            gets large (say, 1,000,000), then computing the pseudoinverse above will take prohibitively long.  This
            means that while important to know, this method of minimizing a linear equation is typically not preferred
            in practice.
        </div>
    <li>
        <em>Back to calculus</em>
        <div class="p">
            Going back to calculus, we end up with the most common (practical) method for minimizing a function, which is a process
            called <em><a href="http://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a></em>.  We calculated
            the gradient earlier, and might remember from calculus that
            <div class="math">
                \vec{x} \cdot \vec{y} = |\vec{x}||\vec{y}| \cos{\theta},
            </div>
            where <span class="math">\vec{x}</span> and <span class="math">\vec{y}</span> are vectors, and
            <span class="math">\theta</span> the angle between them (compare this to the
            <em><a href="http://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality">Cauchy-Schwarz inequality</a></em>).
            The slope of a function <span class="math">f</span> with gradient <span class="math">Df</span> in the
            direction <span class="math">\vec{u}</span> is <span class="math">f \cdot \vec{u}</span>. Since cosine has a
            minimum of -1 when two vectors point in opposite directions, we choose to travel in the direction
            <span class="math">\vec{u} = -Df</span> in order to "decrease" <span class="math">f</span> as quickly
            as possible. This process is called gradient descent, and may be written in pseudocode as
        </div>
            <pre><code>
                step_size = 0.001
                x_new = 0
                x_old = 100
                while abs(x_new - x_old) > 0.01:
                    x_old = x_new
                    x_new = x_new - step_size * gradient(f)(x_new)
                print(x_new)
            </code></pre>
        <div class="p">
            Anyways, we'll assume you (or your computer) know how to minimize functions from here on out.
        </div>
    </li>
</ol>

<h2><a href="#modelBuilding" name="modelBuilding">></a>Model Building</h2>
<div class="p">
    Armed with our newfound knowledge, a great way of working seems to be to take our data set, create a ton of
    basis functions, and fit a model with very low error.  Unfortunately, we then move from our training data to some
    real data, we may find that our model performs spectacularly poorly. This phenomena is called
    <em><a href="http://en.wikipedia.org/wiki/Overfitting">overfitting</a></em>.
</div>

<div class="p">
    We provide a sandbox below to fit a linear model to some sample data, this time with nonlinear basis functions.  You may choose how many basis functions to
    use, and there is a solver running in the background which will find the best fit.  We additionally use 100 points
    sampled from the same function as the training data to compute your mean error.  You can see graphically below when
    the model looks overfit, but in the real world, <span class="math">x</span> will be a vector of dimension greater
    than two, and visualizing your fit in this manner will be difficult.  We'll discuss better ways to detect
    overfitting later. Click on the plot to generate a new training set.
</div>

<div ng-controller="NaiveModelCtrl" class="figure">
    <plot-line-points line-data="plotModel" point-data="trainModel" ng-click="randomFunc()"></plot-line-points>
    <span katex-bind="tex"></span>
    <div>
        <div style="display: inline-block">
            <h3>Basis Functions</h3>
            <div ng-repeat="(key, value) in basisCounts">
                <span> <label>{{key}} bases: </label> <input type="number" min="0" step="1" ng-model=value ng-change="updateBasis(key, value)"></span>
            </div>
        </div>
        <div style="display: inline-block">
            <h3>Error</h3>
            <div>
                Training: {{errors.train.toFixed(4)}}
            </div>
            <div>
                Testing: {{errors.test.toFixed(4)}}
            </div>
        </div>
    </div>
</div>

<div class="p">
    A less naive approach (and one you likely found on your own) would be recognizing that we'll be judged on our
    performance on this test or real data, and plan for this.  So let's first split our data into a "training" and
    "testing" set, then create a ton of basis functions.  Now instead of creating one function with very low training
    error, we will choose successive subsets of our basis functions, and choose the model that has the lowest testing
    error.  We say that this model (that is, the model with lowest testing error) <em>generalizes</em> well.  This is a
    good approach, but if we have, say, 1000 basis functions, testing all
    <span class="math">2^{1000} \approx 10^{300}</span> possible subsets of these is prohibitive (in general, any number
    over <span class="math">10^8</span> should make you at least hesitate).
</div>

<div class="p">
    Our least naive (and often used in practice) approach involves what is called <em>regularization</em>, and is the
    whole point of this essay.  We design a smarter loss function which penalizes a model for being too complicated,
    and (mostly) automatically(-ish) picks a good model for us.  In particular, we will minimize either
    <div class="math">
        loss(\vec{w}) = \sum_{j=1}^d (y_j - \vec{w} \cdot \vec{\phi}(\vec{x}_j))^2 + \alpha \|\vec{w}\|_2^2
    </div>
    or
    <div class="math">
        loss(\vec{w}) = \sum_{j=1}^d (y_j - \vec{w} \cdot \vec{\phi}(\vec{x}_j))^2 + \alpha \|\vec{w}\|_1,
    </div>

    where
    <div class=math>
        \|\vec{w}\|_p := \left(\sum w_j^p \right)^{\frac{1}{p}}
    </div>
    is called the <span class="math">l_p</span>-norm of a vector <span class="math">\vec{w}</span>, and
    <span class="math">\alpha</span> is called the <em>regularization strength</em>.  Using the first loss
    function to train a model is called <em>Ridge regression</em>, and the second is called <em>Lasso</em> regression.
    Note that the <span class="math">l_1</span>-norm is just the sum of the absolute values, and the
    <span class="math">l_2</span>-norm squared is the sum of squares.
</div>

<div class="p">
    Below, we give you the same sandbox as earlier, but you may now also choose the type of regularization to apply,
    and the regularization strength.
</div>

<div ng-controller="RegularModelCtrl" class="figure">
    <plot-line-points line-data="plotModel" point-data="trainModel" ng-click="randomFunc()"></plot-line-points>
    <span katex-bind="tex"></span>
    <div>
        <div style="display: inline-block">
            <h3>Basis Functions</h3>
            <div ng-repeat="(key, value) in basisCounts">
                <span> <label>{{key}} bases: </label> <input type="number" min="0" step="1" ng-model=value ng-change="updateBasis(key, value)"></span>
            </div>
        </div>
        <div style="display: inline-block">
            <h3>Model Type</h3>
            <select ng-model="modelType" ng-options="model.name for model in modelTypes"></select>
        </div>
        <div style="display: inline-block">
            <h3>Regularization Strength</h3>
            <span>
                <label>Regularization Strength: </label>
                <input type="number" min="0" step="0.01" ng-model=regStrength ng-change="updateC(regStrength)">
            </span>
        </div>
        <div style="display: inline-block">
            <h3>Error</h3>
            <div>
                Training: {{errors.train.toFixed(4)}}
            </div>
            <div>
                Testing: {{errors.test.toFixed(4)}}
            </div>
        </div>
    </div>
</div>


<div class="p">
    To get our best model, we still have to choose a value for <span class="math">\alpha</span>, and which type of
    regularization we want (Ridge or Lasso or none), and in order to do this, we will typically write a loop like this:
</div>
    <pre><code>
        errors = []
        for penalty in (None, 'l1', 'l2'):
            for alpha in (0.001, 0.03, 0.1, 0.3, 1):
                model = linear_regression.fit(training_data, penalty, constant)
                errors.append(
                sum(model.fit(testing_data.features) - testing_data.labels) ** 2
                )
    </code></pre>
<div class="p">
    Choosing the set of parameters with the least testing errors gives us our desired model.  We let you choose the
    set of basis vectors we consider when fitting a model, and provide a final sandbox that runs (essentially) the
    code above to fit itself.  Click on the diagram to generate a new training set and a new best set of parameters.
</div>

<div ng-controller="BestModelCtrl" class="figure" ng-click="updateModel()">
    <plot-line-points line-data="plotModel" point-data="trainModel" ng-click="randomFunc()"></plot-line-points>
    <span katex-bind="tex"></span>
    <div class="p">
        Fit with {{modelType.name.toLowerCase()}}, and regularization constant of {{regStrength.toFixed(5)}}.  Training
        error is {{errors.train.toFixed(4)}}, and testing error is {{errors.test.toFixed(4)}}.
    </div>
</div>


<div class="p">
    As a point of fact, we will typically actually divide our data into training, cross validation, and testing sets.
    The model will be trained (with a regularization penalty) on the training set, then we choose the model which
    has the least loss (without a regularization penalty) on the cross validation set.  The testing set will tell
    us what sort of performance to expect in the future.  This is necessary since we may test enough parameters to
    "overfit" on the cross validation set.  In general, we'd expect
    <div class="math">
        \text{training error} < \text{cross validation error} < \text{testing error}.
    </div>
</div>

<h2><a href="#bayesianLoss" name="bayesianLoss">></a>A Bayesian Approach</h2>
<div class="p">
    Previously, we accepted that we would try to minimize the squared loss, because it seemed reasonable.  Later, we
    added various penalties because <em>they</em> seemed reasonable.  It turns out we can make explicit certain
    assumptions about our data, and in fact derive that we then <em>must</em> use these loss functions.
</div>


<div class="p">
    A strategy that is startlingly effective in mathematics is to imagine we know the solution, and see what properties
    the solution must satisfy.  In this case, we'll find it useful to imagine we knew how our data was generated.  A
    reasonable assumption is that our basis functions can capture some, but not all, of the variance in a process, with
    the error being distributed normally. Recall that the probability density function for the normal distribution is
    given by
    <div class="math">
        N(x | \mu, \sigma) = \frac{1}{\sigma \sqrt{2 \pi}}e^{-\frac{(x - \mu)^2}{2 \sigma^2}},
    </div>
    where <span class="math">\mu</span> is the mean value, <span class="math">\sigma</span> is the standard deviation,
    and <span class="math">N(x | \mu, \sigma)</span> is the likelihood of the value <span class="math">x</span>.
    We'll write just <span class="math">N(\mu, \sigma)</span> to represent a variable drawn from this distribution.
    Then our equation for <span class="math">y(x)</span> becomes
    <div class="math">
        y(\vec{x}, \vec{w}) = \vec{w} \cdot \vec{\phi}(\vec{x}) + N(0, \sigma^2),
    </div>
    where the noise represents variables we haven't accounted for, or perhaps measurement error.
</div>

<div class="p">
    Below, we give an example of what this assumption means graphically: we draw some number of data points which are
    located <em>exactly</em> on deterministic function, then we add some normally distributed random number to each
    data point.  In our previous demonstrations, we drew points from the same distributions, with
    <span class="math">\sigma = 0.05</span>.
</div>
<div ng-controller="PointNoiseController" class="figure">
    <plot-noise-points point-data="data"></plot-noise-points>
    <br>
    {{trainingPoints}} points drawn from <span katex-bind="funcName"></span>.
</div>

<div class="p">
    Asking why we think our error is normally distributed is a great question.  Two answers are (1) that the normal
    distribution shows up in
    <a href="http://en.wikipedia.org/wiki/Central_limit_theorem">a surprising number of places</a> ,
    and (2) the resulting problem is analytically tractable,
    meaning it will be instructive if you want to strike out on your own with a more exotic distribution.
</div>

<div class="p">
    In any case, having written down the probability density function for our data, we may ask the <em>likelihood</em>
    of seeing a data point, given our features <span class="math">\vec{x}</span> and weights
    <span class="math">\vec{w}</span>. Namely
    <div class="math">
        p(y | \vec{x}, \vec{w}) = C\exp{\left(-\frac{(y - \vec{w} \cdot \vec{\phi}(\vec{x}))^2}{2 \sigma^2}\right)}.
    </div>
    Since we'll be maximizing functions with respect to <span class="math">\vec{w}</span>, we'll get rid of
    multiplicative factors by grouping them into this constant <span class="math">C</span> whenever possible.
</div>

<div class="p">
    Going further, if we are given a data set
    <div class="math">
        D = \{(y_1, \vec{x}_1),\ldots,(y_d, \vec{x}_d)\},
    </div>
    the probability of seeing this data is the product of seeing each of the individual data points (assuming they are
    drawn independently).  A nice property of the exponential is that this product turns into a sum, and we get
    <div class="math">
        p(D | \vec{w}) = C \exp{\left(-\sum_{j=1}^D\frac{(y_j - \vec{w} \cdot \vec{\phi}(\vec{x}_j))^2}{2 \sigma^2}\right)}.
    </div>
    Notice two things:
</div>
<ol>
    <li>
        This number is extraordinarly small (though that doesn't really matter), and
    </li>
    <li>
        We may choose a <span class="math">\vec{w}</span> to maximize this probability.  This will be called the
        <em>maximum likelihood estimator</em> for <span class="math">\vec{w}</span>, and (spoiler!) will be equivalent
        to minimizing the mean squared error.
    </li>
</ol>

<div class="p">
    In fact, this last statement can be seen through inspection.  If we would like to maximize
    <span class="math">e^{-x}</span>, we would make <span class="math">x</span> as small as possible.  In our above
    example, <span class="math">x</span> is the sum of the squared difference (divided by the standard deviation), so
    the maximum likelihood estimator for <span class="math">w</span> is the weight vector which minimizes
    <div class="math">
        \sum_{j=1}^d(y_j - \vec{w} \cdot \vec{\phi}(\vec{x}_j))^2.
    </div>
</div>

<div class="p">
    This might be considered a <em>frequentist</em> approach to this regression problem: we were given some data, and
    chose our parameters to maximize the probability of seeing that data given the weights.  What if instead, we made
    some assumptions about our weights, and maximized instead the probability of seeing our weights given our data.
    Those with enough schooling will hear that and get nervous that Bayes' Theorem is about to show up.  Indeed, the
    easiest way to remember Bayes' Theorem is to recall that it has something to do with the symmetry of
    <span class="math">p(A, B)</span>, where <span class="math">A</span> and <span class="math">B</span> are some
    events.  In particular, we just need to know that
</div>
<ol>
    <li>
        <span class="math">p(A,B) = p(B,A)</span>, and
    </li>
    <li>
        <span class="math">p(A,B) = p(A | B) p(B)</span>.
    </li>
</ol>
<div class="p">
    Then we get that <span class="math">p(A | B) p(B) = p(A,B) = p(B,A) = p(B | A) p(A)</span>.  Dividing through gives
    the typical expression of Bayes' Theorem
    <div class="math">
        p(A|B) = \frac{p(B | A) p(A)}{p(B)}.
    </div>
</div>

<div class="p">
    Back to the problem at hand, we already calculated <span class="math">p(D | \vec{w})</span>, so we might like to
    write down some prior for our weights, <span class="math">p(\vec{w})</span>.  In particular, recalling our strategy
    outlined earlier of making just a boatload of basis functions, we might imagine that no weight ought to be
    particularly large.  More specifically, that it is <em>unlikely</em> that a large weight occurs.  Then perhaps we
    have a normal prior on our weights, with mean 0 and some spread controlled by <span class="math">\tau</span>:
    <div class="math">
        p(w_j|\tau) = N(0, \tau).
    </div>
    If we in fact expect the weights to be mostly 0, then the Laplace prior with mean 0 and spread
    <span class="math">\tau</span> might be more reasonable, where the probability density function for the Laplace
    distribution is given by
    <div class="math">
        \text{Laplace}(x | \mu, \sigma) = \frac{1}{2 \sigma}e^{-\frac{|x - \mu|}{\sigma}}.
    </div>
    Specifically, we make the assumption that
    <div class="math">
        p(w_j|\tau) = \text{Laplace}(0, \tau).
    </div>
</div>

<div class="p">
    Going back to Bayes' theorem,
    <div class="math">
        p(\vec{w} | D, \tau) = C p(D | \vec{w}, \tau) p(\vec{w}| \tau).
    </div>
    We had great success with the minimizing negative log likelihood earlier, so trying that again turns this
    multiplication into addition, and gives
    <div class="math">
        -\log{\left(p(\vec{w} | D, \tau)\right)} = C - \log{\left(p(D | \vec{w}, \tau)\right)} - \log{\left(p(\vec{w}, \tau)\right)},
    </div>
    which by our earlier calculations means

    <div class="math">
        -\log{\left(p(\vec{w} | D, \tau)\right)} = C + \frac{\sum (y_j - \vec{w} \cdot \vec{x}_j)^2}{2 \sigma^2} - \log{\left(p(\vec{w}, \tau)\right)}
    </div>

</div>
<div class="p">
    Dropping the constant <span class="math">C</span> (since changing <span class="math">w</span> doesn't change
    <span class="math">C</span>), we may just calculate the negative log of the prior on the weights to find an equation
    to minimize that will give us optimal weights.  In particular,
    <div class="math">
        -\log{N(0, \sigma)} = C + \frac{\|\vec{w}\|^2}{2 \sigma^2},
    </div>
    so the weights that best reflect the belief that
    <div class="math">
        y(\vec{x}, \vec{w}) = \vec{w} \cdot \vec{\phi}(\vec{x}) + N(0, \sigma^2)
    </div>
    in light of the data <span class="math">D</span> are those which minimize
    <div class="math">
        \sum_{j=1}^D (y_j - \vec{w} \cdot \vec{x}_j)^2 + \alpha \|\vec{w}\|_2^2,
    </div>
    where <span class="math">\alpha</span> is some constant. This is exactly <em>Ridge regression</em>, as defined
    earlier.  Notice if we were a little more careful, we could write down <span class="math">\alpha</span> as a
    function of <span class="math">\sigma</span> and <span class="math">\tau</span>, but in practice it is difficult
    to think of a great use for recovering those numbers.
</div>

<div class="p">
    Similarly, taking the negative log of the Laplace prior on the weights will leave us with Lasso regression.  Again,
    we have the extra intuition that maximizing the probability of our weights given the data (and the assumption that
    the weights are Laplace distributed) is equivalent to minimizing
    <div class="math">
        \sum_{j=1}^D (y_j - \vec{w} \cdot \vec{x}_j)^2 + \alpha \|\vec{w}\|_1.
    </div>
</div>

<h2><a href="#regularizationGeometry" name="regularizationGeometry">></a>The Geometry of Regularization</h2>
<div class="p">
    As a pleasant conclusion, there is also some beautiful geometry to regularization.  Namely, each of Ridge regression
    and Lasso regression seeks to minimize a weighted average between two different norms.  This weighted average is the
    <span class="math">l^2</span> distance between <span class="math">y(\vec{x}_j, \vec{w})</span> and
    <span class="math">y_j</span> plus the <span class="math">l^1</span>- or <span class="math">l^2</span>-size of
    <span class="math">\vec{w}</span>. It turns out the the unit ball defined by the <span class="math">l^p</span>-norm
    is a circle with <span class="math">p = 2</span>, a diamond when <span class="math">p=1</span>, and gets close to a
    square as <span class="math">p \to \infty</span>.  Intuitively, the unit ball gets "spikier" as
    <span class="math">p</span> gets smaller.  Then it is more likely that the (round) ball around
    <span class="math">y(\vec{x}_j, \vec{w})</span> will meet the (diamond) ball around the origin on one of the axes,
    which leads to a more "sparse" solution for <span class="math">\vec{w}</span>.
</div>
<div ng-controller="EllPController" class="figure">
    <plot-line line-data="data"></plot-line>
    A plot of the set <span katex-bind="funcName"></span>.  Note that as <span class="math">p \to 0</span>, the unit
    <span class="math">l^p</span> ball gets "spikier".
</div>

</body>

<script>
    (function(){
        $(".math").each(function() {
            var texTxt = $(this).text();
            el = $(this).get(0);
            if(el.tagName == "DIV"){
                addDisp = "\\displaystyle";
            } else {
                addDisp = "";
            }
            try {
                katex.render(addDisp+texTxt, el);
            }
            catch(err) {
                $(this).html("<span class='err'>"+err);
            }
        });
    })();
</script>

</html>
