<!doctype html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8">

    <title>
        Bayesian Linear Regression
    </title>

    <!-- CDNs -->
    <!-- AngularJS -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/angular.js/1.2.20/angular.min.js"></script>

    <!-- D3js -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.4.11/d3.min.js"></script>

    <!-- MathJax -->
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script>


    <!--&lt;!&ndash; Local Development &ndash;&gt;-->
    <!--&lt;!&ndash; AngularJS &ndash;&gt;-->
    <!--<script type="text/javascript" src="/js/jquery.min.js"></script>-->
    <!--<script type="text/javascript" src="/js/angular.js"></script>-->

    <!--&lt;!&ndash; D3js &ndash;&gt;-->
    <!--<script type="text/javascript" src="/js/d3.min.js"></script>-->

    <!--&lt;!&ndash; MathJax &ndash;&gt;-->
    <!--<script src="/js/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->

    <!-- Essay -->
    <style>
        @import url("css/custom.css");
    </style>
    <script type="text/javascript" src="/js/talk.js"></script>

</head>
<body ng-app="regressionEssay">
<header>
    <aside>September 18, 2014</aside>
    <a href="colindcarroll.com">Colin Carroll</a>
</header>
<h1>A Bayesian Approach to \(L^1\) and \(L^2\) Regularization in Machine Learning</h1>
<h3>Colin Carroll</h3>

<h2><a href="#introduction" name="introduction">></a>Introduction</h2>
<p>
    There are two common tasks in machine learning: these are <em>regression</em> tasks and <em>classification</em>
    tasks.  Examples of classification tasks include predicting the species of an iris based on
    <a href="http://en.wikipedia.org/wiki/Iris_flower_data_set">petal and sepal measurements</a>, predicting who will
    win a <a href="http://fivethirtyeight.com/interactives/senate-forecast/">Senate race</a> or
    <a href="http://www.lasvegas.com">football game</a>, or predicting who will click on a banner advertisement.
    Broadly each takes some set of inputs and output one of a discrete set of labels (typically, the output will
    actually be a probability of some data point having some label).  A regression task will actually predict a real
    valued output.  Perhaps this would be used to estimate stock prices, forecast inventory, or predict the score of a
    a football game.
</p>

<p>
    Linear regression can get a bad rap for sounding boring.  Much like linear algebra, where much emphasis is put on
    solving \(A \mathbf{x} = \mathbf{b}\), studying linear regression -- how to build a model, how to tune a model, and
    what sorts of performance to expect -- can yield impressive results in practice.  In particular, one finds that
    many methods with sexier names are built on top of linear regression.  Neural nets, which seem to be a buzzword
    these days, use linear regression as its building block.
</p>


<h2><a href="#setup" name="setup">></a>Setup</h2>
<p>
    At its most basic, a linear model is one of the form
</p>
$$y(\mathbf{x}, \mathbf{w}) = w_0 + x_1 w_1 + \cdots + w_Dx_D,$$
<p>
    where \(\mathbf{x} = (x_1, \ldots, x_D) \in \mathbb{R}^D \) are called <em>features</em>, and
    \(\mathbf{w} = (w_0, \ldots, w_D) \in \mathbb{R}^D \) are called <em>weights</em>.  One is typically
    given some training data
</p>

$$\mathscr{D} = \{(y_1, \mathbf{x}_1),\ldots,(y_D, \mathbf{x}_D)\},$$
<p>
    and asked to find a model which minimizes
</p>
$$ loss(\mathbf{w}) = \sum_{j=1}^D (y_j - y(\mathbf{x}_j, \mathbf{w}))^2. $$

<p>
    Below, you may click on the plot to generate a random data set, and then manually choose values \(w_0\), \(w_1\) to
    try to fit \(y(x, \mathbf{w}) = w_0 + w_1 x\) to the data.
</p>
<div ng-controller="ManualRegression">
    <div ng-click="cycleData()">
        <plot-line-points point-data="data" line-data="plotData"></plot-line-points>
    </div>
    <p>
        \(w = (w_0, w_1) = \) (<input type="number" step=0.1 ng-model="w0" ng-change="updatePlot()">,  <input type="number" step=0.1 ng-model="w1" ng-change="updatePlot()">)
        <br>
        Current model: y(x, w) =  {{w0}} + {{w1}}x
    </p>
    <p> Current loss: {{error.toFixed(2)}}</p>
</div>

<h2><a href="#advancedSetup" name="advancedSetup">></a>Advanced Setup</h2>

<p>That was likely highly frustrating, since many (most?) data is drawn from some function which relies non-linearly on
    its inputs.  One might consider rainfall in a location as a function of the day of year, which would probably have
    some sort of periodic relationship, or weight of a person given their height, which we might expect has a polynomial
    relationship (since weight is a measure of volume, and height one of length).  We deal with this by fitting our
    model using <em>basis functions</em>, \(\pmb{\phi} = (\phi_1, \ldots, \phi_n)\), where
    \(\phi_j: \mathbb{R}^D \to \mathbb{R}\).  Then we have our model
</p>
$$y(\mathbf{x}, \mathbf{w}) = w_0 + \sum_{j=1}^n w_j \phi_j(\mathbf{x}).$$

<p>Or, by setting \(\phi_0(\mathbf{x}) := 1\), we can write</p>
$$ y = \pmb{\phi}(\mathbf{x}) \cdot \mathbf{w}.$$

<p>In practice, some popular choices for basis functions include</p>
<ul ng-controller="basisCtrl">
    <li><em>Polynomials.</em>
        For a one dimensional feature set, this just means that instead of writing
        \(y = w_0 + w_1 x\), we will now write \(y = w_0 + w_1 x + w_2 x^2 + \cdots + w_n x^n\).  For a larger set of
        features \(\{x_1, \ldots, x_D\}\), you may get the second degree polynomials by defining
        \(\phi_j(\mathbf{x}) = x_j\), and \(\phi_{j,k}(\mathbf{x}) = x_j x_k\). Now you will have \(D~choose~2\) basis
        functions (usually written \(\binom{D}{2}\), and in fact, equal to \(\frac{D(D-1)}{2}\)), and
        $$
        y(\mathbf{w}, \mathbf{x}) = \pmb{\phi}(\mathbf{x}) \cdot \mathbf{w},
        $$
        where \(\pmb{\phi}: \mathbb{R}^D \to \mathbb{R}^{\frac{D (D-1)}{2}}\).

        A shortcoming of polynomials is that they tend to get very large very fast away from points you have trained on,
        since \(\lim_{x\to\pm \infty}|x^j| = \infty\) for any value of \(j\). This can lead to ridiculous predictions.

        <plot-line line-data="polyData"></plot-line>
        <div>
            Edit degree:
            <input type="number" step="1" ng-model="polyDegree" ng-change="updatePoly()">
        </div>
    </li>

    <li> <em>Sigmoids.</em>
        These are a two parameter family of functions, which may be defined casually as having
        an "S" shape, and carefully as being monotone (either always increasing or decreasing), and converging to a
        finite value in either direction.  Concretely, one such family is
        $$
        \sigma_{m,b}(x) = \frac{1}{1 + e^{-m(x + b)}},
        $$
        where \(m\) controls the "spread" of the sigmoid, and \(b\) the "location" (\(\tanh(m(x+b))\) is another
        popular choice for \(\sigma_{m,b}\)).  One might think of a sigmoid feature as effecting some change in an
        \(m\) neighborhood of \(b\).  You might generate many of these by selecting some grid of locations and spreads
        in your feature space.
        <plot-line line-data="sigmoidData"></plot-line>
        <div>
            Edit location:
            <input type="number" step="0.1" ng-model="sigmoidLoc" ng-change="updateSigmoid()">
        </div>
        <div>
            Edit spread:
            <input type="number" step="1" ng-model="sigmoidSpread" ng-change="updateSigmoid()">
        </div>
    </li>

    <li> <em>Gaussians.</em>
        We'll later deal with these in a statistical fashion, but right now they're just a friendly shape.  Similarly
        to sigmoids, these functions have a local effect on a model.  They are again defined as a two parameter family,
        with the parameters controlling spread and location.  We write
        $$
        \phi_{m,b}(x) = e^{\frac{(x - b)^2}{2m^2}}.
        $$
        <plot-line line-data="gaussData"></plot-line>
        <div>
            Edit location:
            <input type="number" step="0.1" ng-model="gaussLoc" ng-change="updateGauss()">
        </div>
        <div>
            Edit spread:
            <input type="number" min="0" step="0.1" ng-model="gaussSpread" ng-change="updateGauss()">
        </div>
    </li>
</ul>

<h2><a href="#fittingModel" name="fittingModel">></a>Fitting the Model</h2>

<p>
    Up until now, we have been using everyone's favorite method of minimizing functions, namely by eyeballin' them.
    The focus of this essay is not optimization, but one bad and two good methods for minimizing functions should be
    mentioned.
</p>


<p>
    First, recall that we are given
    $$\mathscr{D} = \{(y_1, \mathbf{x}_1),\ldots,(y_D, \mathbf{x}_D)\},$$
    have decided on some set of basis functions
    $$
    \pmb{\phi} = (\phi_0, \ldots, \phi_n),
    $$
    and seek to find a vector
    $$
    \mathbf{w} = (w_0, \ldots, w_n)
    $$
    which minimizes the loss function
    $$
    loss(\mathbf{w}) = \sum_{j=1}^D (y_j - \pmb{\phi}(\mathbf{x}_j) \cdot \mathbf{w}))^2.
    $$
    We outline three methods for finding the minimum.
</p>

<ol>
    <li>
        <em>Guessing</em>
        This is a reasonable first try, but ultimately a Bad Idea.  Given a function <code>loss</code> that evaluates
        the loss of a weight, you might write a loop like
        <pre><code>
            best_w, min_loss = -10, loss(-10)
            for w in range(-10, 10, 0.1):
                if loss(w) < min_loss:
                    best_w, min_loss = w, loss(w)
            print(best_w)
        </code></pre>
        Staring at this loop, a few questions might strike you:
        <ul>
            <li>
                Why did we iterate from -10 to 10?  Why not -1 to 1?  Why not -1,000 to 1,000?
            </li>
            <li>
                What if I need more accuracy?
            </li>
            <li>
                What if \(\mathbf{w}\) is high dimensional?  Instead of 200 points to check, we'll have \(200^{n + 1}\),
                which is a big number.
            </li>
        </ul>
        <p>
            There are good answers to these questions, and if you think about them long enough, you might accidentally
            invent calculus. Rather than belabor the point, let's move on to a calculus based approach.
        </p>
    </li>
    <li>
        <em>Calculus and linear algebra</em>
        <p>We're going to swing from an approach where we hope to be wildly lucky - and then will be only approximately
            correct - to one where we're guaranteed to hit the exact answer square on the head.  One recalls that a big
            theme in calculus is finding extreme points. So we can take a derivative of \(loss(\mathbf{w})\) with
            respect to \(\mathbf{w}\), set it equal to zero, and solve for \(\mathbf{w}\).
        </p>
        <p>
            The gradient
            $$
            \nabla_{\mathbf{w}}loss(\mathbf{w}) = 2 \sum_{j = 1}^D(\pmb{\phi}(\mathbf{x}_j)\cdot \mathbf{w} - y_j) \pmb{\phi}(\mathbf{x}_j)
            $$
            can be rewritten using matrix notation by setting
            $$
            \pmb{\Phi} = \left( \begin{array}{cccc}
            \phi_0(\mathbf{x}_1)&\phi_1(\mathbf{x}_1)&\cdots&\phi_n(\mathbf{x}_1)\\
            \phi_0(\mathbf{x}_2)&\phi_1(\mathbf{x}_2)&\cdots&\phi_n(\mathbf{x}_2)\\
            \vdots & \vdots & \ddots & \vdots \\
            \phi_0(\mathbf{x}_D)&\phi_1(\mathbf{x}_D)&\cdots&\phi_n(\mathbf{x}_D)
            \end{array}\right),
            $$
            $$
            \mathbf{y} = \left( \begin{array}{c}
            y_1 \\
            y_2 \\
            \vdots \\
            y_D
            \end{array} \right), \text{ and }
            \mathbf{w} = \left( \begin{array}{c}
            w_0 \\
            w_1 \\
            \vdots \\
            w_n
            \end{array} \right).
            $$
            Now we have \(\pmb{\Phi}^T\pmb{\Phi}\mathbf{w} = \pmb{\Phi}^T\mathbf{y}\).  Note that \(\pmb{\Phi}\) is a
            \(D \times (n + 1)\) matrix, where \(D\) is a big number (in particular, \(D > n + 1\)). However,
            \(\pmb{\Phi}^{T}\pmb{\Phi}\) is an \((n + 1) \times (n+1)\), (probably) invertible matrix.  Then
            Specifically,
            $$
            \begin{array}{rl}
            \pmb{\Phi}^T\pmb{\Phi}\mathbf{w} = & \pmb{\Phi}^T\mathbf{y}\\
            (\pmb{\Phi}^T\pmb{\Phi})^{-1}(\pmb{\Phi}^T\pmb{\Phi})\mathbf{w} =& (\pmb{\Phi}^T\pmb{\Phi})^{-1}\pmb{\Phi}^T\mathbf{y} \\
            \mathbf{w} =& (\pmb{\Phi}^T\pmb{\Phi})^{-1}\pmb{\Phi}^T\mathbf{y}.
            \end{array}
            $$
            This solution will minimize the loss function, and be an exact answer.  Back of the
            envelope calculations say that as \(D\) gets large (say, 1,000,000), then computing the pseudoinverse above
            will take prohibitively long.
        </p>
    <li>
        <em>Back to calculus</em>
        <p>
            Going back to calculus, we end up with the most common solution to minimizing a function, using a process
            called <em>gradient descent</em>.  We calculated the gradient earlier, and might remember from calculus that
            $$
            \mathbf{x} \cdot \mathbf{y} = |\mathbf{x}||\mathbf{y}| \cos{\theta},
            $$
            where \(\mathbf{x}\) and \(\mathbf{y}\) are vectors, and \(\theta\) the angle between them. The slope of a
            function \(f\) with gradient \(\nabla f\) in the direction \(\mathbf{u}\) is \(\nabla f \cdot \mathbf{u}\).
            Since cosine has a minimum of -1 when two vectors point in opposite directions, we choose to travel in
            the direction \(\mathbf{u} = -\nabla f\) in order to "decrease" \(f\) as quickly as possible.  This process
            is called gradient descent, and may be written in pseudocode as
        </p>
            <pre><code>
                step_size = 0.001
                x_new, x_old = 0, 100
                while abs(x_new - x_old) > 0.01:
                x_old = x_new
                x_new = x_new - step_size * gradient(f)(x_new)
            </code></pre>
        <p>
            Anyways, we'll assume you (or your computer) know how to minimize functions from here on out.
        </p>
    </li>
</ol>

<h2><a href="#modelBuilding" name="modelBuilding">></a>Model Building</h2>
<p>
    Armed with our new found knowledge, a great way of working seems to be to take our data set, create a ton of
    basis functions, and fit a model with very low error.  Unfortunately, we then move from our training data to a
    set of (hopefully) test data or (probably) real data, and find we do spectacularly poorly. This phenomena is called
    <em>overfitting</em>.
</p>

<p>
    We provide a sandbox below to fit a linear model to some sample data.  You may choose how many basis functions to
    use, and there is a solver running in the background which will find the best fit.  We additionally use 100 points
    sampled from the same function as the training data to compute your mean error.  You can see graphically below when
    the model looks overfit, but in the real world, \(x\) will be a vector of dimension greater than two, and
    visualizing your fit in this manner will be difficult.  We'll discuss better ways to detect overfitting later.
    Click on the plot to generate a new training set.
</p>

<div ng-controller="NaiveModelCtrl">
    <plot-line-points line-data="plotModel" point-data="trainModel" ng-click="randomFunc()"></plot-line-points>
    <span mathjax-bind="tex"></span>
    <div>
        <div style="display: inline-block">
            <h3>Basis Functions</h3>
            <div ng-repeat="(key, value) in basisCounts">
                <span> <label>{{key}} bases: </label> <input type="number" min="0" step="1" ng-model=value ng-change="updateBasis(key, value)"></span>
            </div>
        </div>
        <div style="display: inline-block">
            <h3>Error</h3>
            <div>
                Training: {{errors.train.toFixed(4)}}
            </div>
            <div>
                Testing: {{errors.test.toFixed(4)}}
            </div>
        </div>
    </div>
</div>

<p>
    A less naive approach (and one you likely found on your own) would be recognizing that we'll be judged on our
    performance on this test or real data, and plan for this.  So let's first split our data into a "training" and
    "testing" set, then create a ton of basis functions.  Now instead of creating one function with very low training
    error, we will choose successive subsets of our basis functions, and choose the model that has the lowest testing
    error.  We say that this model (that is, the model with lowest testing error) <em>generalizes</em> well.  This is a
    good approach, but if we have, say, 1000 basis functions, testing all \(2^{1000} \approx 10^{300}\) possible
    subsets of these is prohibitive (in general, any number over \(10^8\) should make you at least hesitate).
</p>

<p>
    Our least naive (and often used in practice) approach involves what is called <em>regularization</em>, and is the
    whole point of this essay.  We design a smarter loss function which penalizes a model for being too complicated,
    and automatically (mostly) picks a good model for us.  In particular, we will minimize either
    $$
    \sum_{j=1}^D (y_j - \mathbf{w} \cdot \pmb{\phi}(\mathbf{x}_j))^2 + C\|\mathbf{w}\|_2^2
    $$
    or
    $$
    \sum_{j=1}^D (y_j - \mathbf{w} \cdot \pmb{\phi}(\mathbf{x}_j))^2 + C\|\mathbf{w}\|_1,
    $$
    where \(C\) is some constant we have to pick, and
    $$
    \|\mathbf{w}\|_p := \left(\sum w_j^p \right)^{\frac{1}{p}}
    $$
    is called the \(\ell^p\)-norm of a vector \(\mathbf{w}\).  Using the first loss function to train a model is called
    <em>Ridge regression</em>, and the second is called <em>Lasso</em> regression.  Note that the \(\ell^1\)-norm is
    just the sum of the absolute values, and the \(\ell^2\)-norm squared is the sum of squares.
</p>

<p>
    Below, we give you the same sandbox as earlier, but you may now also choose the type of regularization to apply,
    and the regularization strength.
</p>

<div ng-controller="RegularModelCtrl">
    <plot-line-points line-data="plotModel" point-data="trainModel" ng-click="randomFunc()"></plot-line-points>
    <span mathjax-bind="tex"></span>
    <div>
        <div style="display: inline-block">
            <h3>Basis Functions</h3>
            <div ng-repeat="(key, value) in basisCounts">
                <span> <label>{{key}} bases: </label> <input type="number" min="0" step="1" ng-model=value ng-change="updateBasis(key, value)"></span>
            </div>
        </div>
        <div style="display: inline-block">
            <h3>Model Type</h3>
            <select ng-model="modelType" ng-options="model.name for model in modelTypes"></select>
        </div>
        <div style="display: inline-block">
            <h3>Regularization Strength</h3>
            <span>
                <label>Regularization Strength: </label>
                <input type="number" min="0" step="0.01" ng-model=regStrength ng-change="updateC(regStrength)">
            </span>
        </div>
        <div style="display: inline-block">
            <h3>Error</h3>
            <div>
                Training: {{errors.train.toFixed(4)}}
            </div>
            <div>
                Testing: {{errors.test.toFixed(4)}}
            </div>
        </div>
    </div>
</div>


<p>
    To get our best model, we still have to choose a value for \(C\), and which type of regularization we want (Ridge
    or Lasso or none), and in order to do this, we will typically write a loop like this:
</p>
    <pre><code>
        errors = []
        for penalty in (None, 'l1', 'l2'):
            for constant in (0.001, 0.03, 0.1, 0.3, 1):
                model = linear_regression.fit(training_data, penalty, constant)
                errors.append(
                sum(model.fit(testing_data.features) - testing_data.labels) ** 2
                )
    </code></pre>
<p>
    Choosing the set of parameters with the least testing errors gives us our desired model.  We let you choose the
    set of basis vectors we consider when fitting a model [1], and provide a final sandbox that runs (essentially) the
    code above to fit itself.  Add bunches of basis functions, fit a model, and click on the diagram to generate a
    new training set.
</p>

<div ng-controller="BestModelCtrl">
    <plot-line-points line-data="plotModel" point-data="trainModel" ng-click="randomFunc()"></plot-line-points>
    <span mathjax-bind="tex"></span>
    <p>
        Fit with {{modelType.name.toLowerCase()}}, and regularization constant of {{regStrength.toFixed(5)}}.
    </p>
    <div>
        <div style="display: inline-block">
            <h3>Basis Functions</h3>
            <div ng-repeat="(key, value) in basisCounts">
                <span> <label>{{key}} bases: </label> <input type="number" min="0" step="1" ng-model=value ng-change="updateBasis(key, value)"></span>
            </div>
        </div>

        <div style="display: inline-block">
            <h3>Find Best Model</h3>
            <button ng-click="getBestModel()">Click Me!</button>
        </div>

        <div style="display: inline-block">
            <h3>Error</h3>
            <div>
                Training: {{errors.train.toFixed(4)}}
            </div>
            <div>
                Testing: {{errors.test.toFixed(4)}}
            </div>
        </div>
    </div>
</div>


<p>
    As a point of fact, we will typically actually divide our data into training, cross validation, and testing sets.
    The model will be trained (with a regularization penalty) on the training set, then we choose the model which
    has the least loss (without a regularization penalty) on the cross validation set.  The testing set will tell
    us what sort of performance to expect in the future.  This is necessary since we may test enough parameters to
    "overfit" on the cross validation set.  In general, we'd expect
    $$
    \text{training error < cross validation error < testing error}.
    $$
</p>

<h2><a href="#bayesianLoss" name="bayesianLoss">></a>A Bayesian Approach</h2>
<p>
    Previously, we accepted that we would try to minimize the squared loss, because it seemed reasonable.  Later, we
    added various penalties because <em>they</em> seemed reasonable.  It turns out we can make explicit certain
    assumptions about our data, and in fact derive that we then <em>must</em> use these loss functions.
</p>

<aside>
    Recall the probability density function for the normal distribution is given by
    $$\mathscr{N}(x | \mu, \sigma) = \frac{1}{\sigma \sqrt{2 \pi}}e^{-\frac{(x - \mu)^2}{2 \sigma^2}}$$
</aside>
<p>
    A strategy that is startlingly effective in mathematics is to imagine we know the solution, and see what properties
    the solution must satisfy.  In this case, we'll find it useful to imagine we knew how our data was generated.  A
    reasonable assumption is that our basis functions can capture some, but not all, of the variance in a process, with
    the error being distributed normally.  Explicitly,
    $$
    y(\mathbf{x}, \mathbf{w}) = \mathbf{w} \cdot \pmb{\phi}(\mathbf{x}) + \mathscr{N}(0, \sigma^2),
    $$
    where the noise represents variables we haven't accounted for, or perhaps measurement error.
</p>

<p>
    Below, we give an example of what this assumption means graphically: we draw some number of data points which are
    located <em>exactly</em> on deterministic function, then we add some normally distributed random number to each
    data point.
</p>
<div ng-controller="PointNoiseController">
    <plot-noise-points point-data="data"></plot-noise-points>
    <br>
    {{trainingPoints}} points drawn from
    <span mathjax-bind="funcName"></span>
</div>

<p>
    Asking why we think our error is normally distributed is a great question.  Two answers are (1) that the normal
    distribution shows up in
    <a href="http://en.wikipedia.org/wiki/Central_limit_theorem">a surprising number of places</a> ,
    and (2) the resulting problem is analytically tractable,
    meaning it will be instructive if you want to strike out on your own with a more exotic distribution.
</p>

<aside>
    Since we'll be maximizing functions with respect to \(\mathbf{w}\), we'll feel free to drop multiplicative
    factors which don't depend on \(\mathbf{w}\).
</aside>
<p>
    In any case, having written down the probability density function for our data, we may ask the <em>likelihood</em>
    of seeing a data point, given our features \(\mathbf{x}\) and weights \(\mathbf{w}\).  Namely
    $$
    p(y | \mathbf{x}, \mathbf{w}) \propto \exp{\left(-\frac{(y - \mathbf{w} \cdot \phi(\mathbf{x}))^2}{2 \sigma^2}\right)}.
    $$
    Going further, if we are given a data set
    $$
    \mathscr{D} = \{(y_1, \mathbf{x}_1),\ldots,(y_D, \mathbf{x}_D)\},
    $$
    the probability of this data is the product of seeing each of the individual data points (assuming they are drawn
    independently).  A nice property of the exponential is that this product turns into a sum, and we get
    $$
    p(\{y_j\} | \{\mathbf{x}_j\}, \mathbf{w}) \propto \exp{\left(-\sum_{j=1}^D\frac{(y_j - \mathbf{w} \cdot \phi(\mathbf{x}_j))^2}{2 \sigma^2}\right)}.
    $$
    Notice two things:
</p>
<ol>
    <li>
        This number is extraordinarly small (though that doesn't really matter), and
    </li>
    <li>
        We may choose a \(\mathbf{w}\) to maximize this probability.  This will be called the <em>maximum
        likelihood estimator</em> for \(\mathbf{w}\), and (spoiler!) will be equivalent to minimizing the mean squared
        error.
    </li>
</ol>
<p>
    In fact, this last statement can be seen through inspection.  If we would like to maximize \(e^{-x}\), we would make
    \(x\) as small as possible.  In our above example, \(x\) is the sum of the squared difference (divided by the standard
    deviation), so the maximum likelihood estimator for \(\mathbf{w}\) is the weight vector which minimizes
    $$
    \sum_{j=1}^D(y_j - \mathbf{w} \cdot \phi(\mathbf{x}_j))^2.
    $$
</p>

<p>
    This might be considered a <em>frequentist</em> approach to this regression problem: we were given some data, and
    chose our parameters to maximize the probability of seeing that data given the weights.  What if instead, we made
    some assumptions about our weights, and maximized instead the probability of seeing our weights given our data.
    Those with enough schooling will hear that and get nervous that Bayes' Theorem is about to show up.  Indeed, the
    easiest way to remember Bayes Theorem is to recall that it has something to do with the symmetry of \(p(A, B)\),
    where \(A\) and \(B\) are some events.  In particular, we just need to know that
</p>
<ol>
    <li>
        \(p(A,B) = p(B,A)\), and
    </li>
    <li>
        \(p(A,B) = p(A | B) p(B)\).
    </li>
</ol>
<p>
    Then we get that \(p(A | B) p(B) = p(A,B) = p(B,A) = p(B | A) p(A)\).  Dividing through, Bayes' Theorem says
    $$
    p(A|B) = \frac{p(B | A) p(A)}{p(B)}.
    $$
</p>

<aside>
    The probability density function for the Laplace distribution is given by
    $$Laplace(x | \mu, \sigma) = \frac{1}{2 \sigma}e^{-\frac{|x - \mu|}{\sigma}}$$
</aside>
<p>
    Back to the problem at hand, we already calculated \(p(\mathscr{D} | \mathbf{w})\), so we might like to write down
    some prior for our weights, \(p(\mathbf{w})\).  In particular, recalling our strategy outlined earlier of making
    just a boatload of basis functions, we might imagine that no weight ought to be particularly large.  More
    specifically, that it is <em>unlikely</em> that a large weight occurs.  Then perhaps we have a normal prior on our
    weights, with mean 0 and some spread controlled by \(\tau\):
    $$
    p(w_j|\tau) \sim \mathscr{N}(0, \tau).
    $$
    If we in fact expect the weights to be mostly 0, the the Laplace prior might be more reasonable, again with mean
    0 and some spread controlled by \(\tau\):
    $$
    p(w_j|\tau) \sim Laplace(0, \tau).
    $$
</p>

<p>
    Going back to Bayes' theorem,
    $$
    p(\mathbf{w} | \mathscr{D}, \tau) \propto p(\mathscr{D} | \mathbf{w}, \tau) p(\mathbf{w}| \tau).
    $$
    We had great success with the minimizing negative log likelihood earlier, so trying that again turns this
    multiplication into addition, and gives
    $$
    \begin{align}
    -\log{\left(p(\mathbf{w} | \mathscr{D}, \tau)\right)} &\propto -\log{\left(p(\mathscr{D} | \mathbf{w}, \tau)\right)} - \log{\left(p(\mathbf{w}, \tau)\right)} \\
    &= \frac{\sum (y_j - \mathbf{w} \cdot \mathbf{x}_j)^2}{2 \sigma^2} - \log{\left(p(\mathbf{w}, \tau)\right)}
    \end{align}
    $$
    Taking the negative log of the normal prior on the weights tells us that maximizing the probability of our weights
    given the data is equivalent to minimizing

    $$
    \sum_{j=1}^D (y_j - \mathbf{w} \cdot \mathbf{x}_j)^2 + C \|\mathbf{w}\|_2^2.
    $$
    This is exactly <em>Ridge regression</em>, as defined earlier.  Notice if we were a little more careful, we could
    write down \(C\) as a function of \(\sigma\) and \(\tau\), but in practice it is difficult to think of a great use
    for recovering those numbers.
</p>

<p>
    Similarly, taking the negative log of the Laplace prior on the weights will leave us with Lasso regression.  Again,
    we have the extra intuition that maximizing the probability of our weights given the data (and the assumption that
    the weights are Laplace distributed) is equivalent to minimizing
    $$
    \sum_{j=1}^D (y_j - \mathbf{w} \cdot \mathbf{x}_j)^2 + C \|\mathbf{w}\|_1.
    $$
</p>

<h2><a href="#regularizationGeometry" name="regularizationGeometry">></a>The Geometry of Regularization</h2>
<p>
    As a pleasant aside, there is also some beautiful geometry to regularization.  Namely, each of Ridge regression and
    Lasso regression seeks to minimize a weighted average between two different norms.  This weighted average
    is the \(\ell^2\) distance between \(y(\mathbf{x}_j, \mathbf{w})\) and \(y_j\) plus the \(\ell^1\)- or
    \(\ell^2\)-size of \(\mathbf{w}\).  It turns out the the unit ball
    defined by the \(\ell^p\)-norm is a circle with \(p = 2\), a diamond when \(p  =1\), and gets close to a square as
    \(p \to \infty\).  Intuitively, the unit ball gets "spikier" as \(p\) gets smaller.  Then it is more likely that the
    (round) ball around \(y(\mathbf{x}_j, \mathbf{w})\) will meet the (diamond) ball around the origin on one of the
    axes, which leads to a more "sparse" solution for \(\mathbf{w}\).
</p>
<div ng-controller="EllPController">
<plot-line line-data="data"></plot-line>
     <input type="number" min="0" step="0.1" ng-model=p ng-change="update()"></span>
    A plot of the set <span mathjax-bind="funcName"></span>.  Note that as \(p \to 0\), the unit \(\ell^p\) ball gets
    "spikier".
    </div>
</body>
</html>
